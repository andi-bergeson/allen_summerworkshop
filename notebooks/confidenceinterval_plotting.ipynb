{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1382d984-da7a-4a2b-b741-27c88ddf933d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from caveclient import CAVEclient\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels as sm\n",
    "from statsmodels.stats import proportion\n",
    "import warnings\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e93e059-1a7b-4172-a4bc-a47fb95d1f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tables(pre_df):\n",
    "    # using this as the only place to pull pre-syn's from because it's well-proofread\n",
    "    presyn_df = ['allen_v1_column_types_slanted']\n",
    "    df = client.materialize.query_table(presyn_df[0],split_positions=True)\n",
    "    # post-synaptic partners of starter cell\n",
    "    pre_root_id = np.array(pre_df.pt_root_id)[0]\n",
    "    syn_unfiltered = client.materialize.query_table('synapses_pni_2',\n",
    "                                                filter_equal_dict={'pre_pt_root_id':pre_root_id})\n",
    "    # if updated, this will change\n",
    "    correct_soma_table = client.info.get_datastack_info()['soma_table']\n",
    "    # x, y, and z will have their own columns\n",
    "    nuclei_unmasked = client.materialize.query_table(correct_soma_table,split_positions=True)\n",
    "    # new df of just neurons (no glial cells)\n",
    "    nuclei = nuclei_unmasked.query('cell_type == \"neuron\"').reset_index(drop=True)\n",
    "    # new column saying how many neurons have the same root_id\n",
    "    nuclei['num_soma'] = nuclei.groupby('pt_root_id').transform('count')['valid']\n",
    "    # mask the df to throw out merged nuclei (same root_id being assigned to multiple neurons)\n",
    "    mask_nuclei = nuclei['num_soma'] < 2\n",
    "    nuclei_full = nuclei[mask_nuclei].reset_index(drop=True)\n",
    "    # grabbing the unique root_id's of single-body neurons\n",
    "    unique_nuc = np.unique(nuclei_full.pt_root_id)\n",
    "    # masking the cell type table for only single-body neurons\n",
    "    soma_full = client.materialize.query_table('allen_soma_coarse_cell_class_model_v1',\n",
    "                                               filter_in_dict = {'pt_root_id':unique_nuc},\n",
    "                                               split_positions=True)\n",
    "    # masking the synapse table for only single-body neurons\n",
    "    syn_nuc = syn_unfiltered.query(\"post_pt_root_id in @unique_nuc\").reset_index(drop=True)\n",
    "    # new column in synapse table = number of synapses per single soma\n",
    "    syn_nuc['num_syn'] = syn_nuc.groupby('post_pt_root_id').transform('count')['valid']\n",
    "    # renaming post_pt_root_id in order to merge correctly\n",
    "    syn_nuc.rename(columns={'post_pt_root_id':'pt_root_id'}, inplace=True)\n",
    "    # merge!\n",
    "    new_left = pd.merge(soma_full,syn_nuc,on='pt_root_id',how='left')\n",
    "    # *** this will change in the future. I'm losing info abt synapse positions & sizes in this step\n",
    "    main = new_left.drop_duplicates(subset='pt_root_id', keep='first').reset_index(drop=True)\n",
    "    # these columns are useless to me\n",
    "    main = main.drop(columns=['id_y', 'valid_y', 'pre_pt_supervoxel_id', 'post_pt_supervoxel_id', \n",
    "                              'pre_pt_position', 'post_pt_position'])\n",
    "    main = main.fillna(0)\n",
    "    # add new columns for euclidean & radial distance to root_id's \n",
    "    main['d'] = Eucdistance_split(pre_df,main)\n",
    "    main['r'] = Raddistance_split(pre_df,main)\n",
    "    # grabbing the unique root_id's of single-body neurons in the synapse table\n",
    "    unique_syn_nuc = np.unique(syn_nuc.pt_root_id)\n",
    "    # new tables sorted from main of synaptic targets or non-synaptic neighbors of pre_root_id\n",
    "    syn = main.query('pt_root_id in @unique_syn_nuc')\n",
    "    nonsyn = main.query('pt_root_id not in @unique_syn_nuc')\n",
    "    return main,syn,nonsyn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3b0ac8-7165-44bb-93ed-0b9125aaf1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_spitter(df):\n",
    "    classes = np.unique(df.classification_system)\n",
    "    cellarray = []\n",
    "    for i in range(len(classes)):\n",
    "        new = df.query(f\"classification_system in @classes[{i}]\").reset_index(drop=True)\n",
    "        cellarray.append(new)\n",
    "    return cellarray\n",
    "\n",
    "def type_spitter(df):\n",
    "    types = np.unique(df.cell_type)\n",
    "    cellarray = []\n",
    "    for i in range(len(types)):\n",
    "        new = df.query(f\"cell_type in @types[{i}]\").reset_index(drop=True)\n",
    "        cellarray.append(new)\n",
    "    return cellarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df76052-35a4-4815-82e6-7436625af531",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Eucdistance_split(pre,post):\n",
    "    x_pre,y_pre,z_pre = np.array(pre.pt_position_x)*4,np.array(pre.pt_position_y)*4,np.array(pre.pt_position_z)*40\n",
    "    x_pos,y_pos,z_pos = np.array(post.pt_position_x)*4,np.array(post.pt_position_y)*4,np.array(post.pt_position_z)*40\n",
    "    d = np.zeros(len(post))\n",
    "    for i in range(len(post)):\n",
    "        # divide by 1000 to convert to microns\n",
    "        d[i] = np.sqrt((x_pre-x_pos[i])**2 + (y_pre-y_pos[i])**2 + (z_pre-z_pos[i])**2) / 1000.\n",
    "    return d\n",
    "\n",
    "def Raddistance_split(pre,post):\n",
    "    x_pre,z_pre = np.array(pre.pt_position_x)*4,np.array(pre.pt_position_z)*40\n",
    "    x_pos,z_pos = np.array(post.pt_position_x)*4,np.array(post.pt_position_z)*40\n",
    "    d = np.zeros(len(post))\n",
    "    for i in range(len(post)):\n",
    "        # divide by 1000 to convert to microns\n",
    "        d[i] = np.sqrt((x_pre-x_pos[i])**2 + (z_pre-z_pos[i])**2) / 1000.\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595c61f9-eb1e-4fb0-8c5c-6afc13056f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binomial_CI(df, bins):\n",
    "    fail = []\n",
    "    success = []\n",
    "    # no cells are less than 0 microns away, and this makes sure my arrays are the same size\n",
    "    fail.append(0)\n",
    "    success.append(0)\n",
    "    for i in range(len(bins)-1):\n",
    "        # masking for specific distance bin\n",
    "        masked_df = df[(df['r'] < bins[i+1]) & (df['r'] > bins[i])].reset_index(drop=True)\n",
    "        # starting the counter\n",
    "        f,s = 0,0\n",
    "        for j in range(len(masked_df)):\n",
    "            if masked_df['pre_pt_root_id'][j] == 0:\n",
    "                f += 1\n",
    "            else:\n",
    "                s += 1\n",
    "        # if there are zero cells in masked_df, 0's are appended\n",
    "        fail.append(f)\n",
    "        success.append(s)\n",
    "    return np.array(fail),np.array(success)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e053fc44-5177-4135-bb27-ee35d14a1bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def threepanels_pertype(bins,syn_types,nonsyn_types,pre,filename):\n",
    "    warnings.filterwarnings('ignore')\n",
    "\n",
    "    fig, ax = plt.subplots(len(unique_types),3)\n",
    "    fig.set_size_inches(12,26)\n",
    "\n",
    "    x = bins-(r_interval/2)\n",
    "    for i in range(len(unique_types)):\n",
    "        sns.scatterplot(x=nonsyn_types[i].pt_position_x*(4/1000), y=nonsyn_types[i].pt_position_z*(40/1000), \n",
    "                        ax=ax[i,0], color='grey', alpha=.4, s=10)\n",
    "        sns.scatterplot(x=syn_types[i].pt_position_x*(4/1000), y=syn_types[i].pt_position_z*(40/1000), \n",
    "                        ax=ax[i,0], color='b', alpha=.8, s=10).set_xlabel(r'$\\mu$m')\n",
    "        sns.scatterplot(x=pre.pt_position_x*(4/1000), y=pre.pt_position_z*(40/1000), marker='*',color='r',s=200,\n",
    "                        ax=ax[i,0]).set_ylabel(unique_types[i], fontsize=16)\n",
    "        xrange = [int(pre.pt_position_x*(4/1000))-250,int(pre.pt_position_x*(4/1000))+250]\n",
    "        yrange = [int(pre.pt_position_z*(40/1000))-250,int(pre.pt_position_z*(40/1000))+250]\n",
    "        ax[i,0].set_xlim(xrange[0],xrange[1])\n",
    "        ax[i,0].set_ylim(yrange[0],yrange[1])\n",
    "        ax[i,0].set_aspect('equal')\n",
    "\n",
    "        method = 'wilson'\n",
    "        errorbars = sm.stats.proportion.proportion_confint(s_type[i],nobs=(s_type[i]+f_type[i]),method=method)\n",
    "        probability = (s_type[i]/(f_type[i]+s_type[i]))\n",
    "        ax[i,1].scatter(x=x, y=probability)\n",
    "        ax[i,1].errorbar(x=x, y=probability, yerr=(probability-errorbars[0],errorbars[1]-probability), fmt='-o') \n",
    "        ax[i,1].set_xlabel(r'$\\mu$m (radial)', fontsize=10)\n",
    "        ax[i,1].set_ylabel(\"Probability of Connection\", fontsize=10)\n",
    "        ax[i,1].set_ylim(-0.1,1.)\n",
    "        ax[i,1].grid()\n",
    "\n",
    "        ax[i,2].hist(x,bins=len(bins),weights=f_type[i]+s_type[i],density=False,label='Non-Synaptic', color='grey')\n",
    "        ax[i,2].hist(x,bins=len(bins),weights=s_type[i],density=False,label='Synaptic', color='blue')\n",
    "        ax[i,2].set_yscale('log')\n",
    "        ax[i,2].set_xlabel(r'$\\mu$m (radial)', fontsize=10)\n",
    "        ax[i,2].set_xlim(-10,(max(bins_25)+10))\n",
    "        ax[i,2].grid()\n",
    "        ax[i,2].set_ylabel(\"Log Frequency\", fontsize=10)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    fig.savefig('{0:s}.pdf'.format(filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf77bd50-2091-4ab3-9af3-0b3195dc64b9",
   "metadata": {},
   "source": [
    "### Careful! Read https://annotationframeworkclient.readthedocs.io/en/stable/guide/authentication.html#new-token if this does not work for you!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982feb78-6932-4fe2-8afd-6c4c4971f507",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = CAVEclient(global_only=True)\n",
    "client = CAVEclient('minnie65_phase3_v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eff6329-5067-4aaf-9ee0-cf8805972784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using this as the only place to pull pre-syn's from because it's well-proofread\n",
    "presyn_df = ['allen_v1_column_types_slanted']\n",
    "df = client.materialize.query_table(presyn_df[0],split_positions=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b45f69e-330a-41bf-9205-7962d4c93fb6",
   "metadata": {},
   "source": [
    "Put your pre-synaptic root_id's here..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa146f9-4a9f-4456-b175-961a593e52f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_root_ids = [864691135428608048]\n",
    "pre = []\n",
    "for i in range(len(pre_root_ids)):\n",
    "    pre_grab = df.query(f\"pt_root_id == @pre_root_ids[{i}]\")\n",
    "    pre.append(pre_grab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed9ca02-ed0e-4026-b1fd-78f9ce24b2f3",
   "metadata": {},
   "source": [
    "Or grab from the proofread df!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25cb63c-8ee8-4d2c-8271-1845812a3588",
   "metadata": {},
   "outputs": [],
   "source": [
    "optional_pre = df.query(\"cell_type == '5P_IT'\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79fb8f22-2d27-4b69-8224-fff7dd5d6054",
   "metadata": {},
   "source": [
    "The following function, build_tables, takes only 1 input, and that is one pre-synaptic cell. The function outputs 3 things, all pandas tables containing confirmed single-body somas that have been analyzed by Forrest & Leila and categorized as 1 out of 11 possible subtypes: \n",
    "\n",
    "1. a \"main\" table containing all of the above,\n",
    "2. a \"syn\" table containing only neurons connecting to whichever pre-synaptic cell was given,\n",
    "3. a \"nonsyn\" table containing only neurons that are NOT connected to the pre-synaptic cell.\n",
    "\n",
    "All three have their positions split into x,y,z and all have columns corresponding to their Euchlidean and Radial distance from the pre-synaptic cell. In the main table, if their \"pre_pt_root_id\" equals zero, that means they are not in the post-synaptic table, and not connected to the pre-synaptic root_id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ee8b17-3522-43cf-92b7-ff110fddb6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "main,syn,nonsyn = [],[],[]\n",
    "for i in range(len(pre)):\n",
    "    m,s,n = build_tables(pre[i])\n",
    "    main.append(m)\n",
    "    syn.append(s)\n",
    "    nonsyn.append(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f05334-aac5-4cde-983f-5640b9dbffd8",
   "metadata": {},
   "source": [
    "The following functions will take the tables generated above and split them into class-specific or type-specific tables. \n",
    "\n",
    "The tables will be referenced as such: \n",
    "\n",
    "- main_class[0] will contain two class-specific tables for your first pre-synaptic root_id\n",
    "- syn_types[1][3] will contain a single table of cells of the fourth specific type for your second pre-synaptic root_id, and only contain the ones connected to your pre-syn cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00515bb9-00d6-4b1e-81a5-fdf7d1969623",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_class,syn_class,nonsyn_class = [],[],[]\n",
    "main_types,syn_types,nonsyn_types = [],[],[]\n",
    "for i in range(len(pre)):\n",
    "    m_c = class_spitter(main[i])\n",
    "    s_c = class_spitter(syn[i])\n",
    "    n_c = class_spitter(nonsyn[i])\n",
    "    main_class.append(m_c)\n",
    "    syn_class.append(s_c)\n",
    "    nonsyn_class.append(n_c)\n",
    "    \n",
    "    m_t = type_spitter(main[i])\n",
    "    s_t = type_spitter(syn[i])\n",
    "    n_t = type_spitter(nonsyn[i])\n",
    "    main_types.append(m_t)\n",
    "    syn_types.append(s_t)\n",
    "    nonsyn_types.append(n_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91052ab-64a2-4832-97d2-c5be904a4e96",
   "metadata": {},
   "source": [
    "The following will be used for constructing the confidence interval.\n",
    " - r_interval is the bin width for each radial ring (in microns)\n",
    " - upper_distance_limit, again in microns, is the radial distance away from your pre-synaptic cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf392a35-6546-4616-a04d-c0c262c9c054",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_interval = 25\n",
    "upper_distance_limit = 400\n",
    "bins_25 = np.array(range(0,upper_distance_limit,r_interval))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ebdc15-c695-4912-b26c-70795f5d55c9",
   "metadata": {},
   "source": [
    "The following function binomial_CI takes a table, checks if each cell has a pre-synaptic root_id in a given radial distance, and creates two arrays of bin length:\n",
    "\n",
    "- f_type, containing the number of cells per bin not connected (failure), and \n",
    "- s_type, containing the number of cells per bin that IS connected (success)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6912bb3-55a4-4f06-8567-e7949c3826cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_type,s_type = [],[]\n",
    "# synf_type,syns_type = [],[]\n",
    "# nonsynf_type,nonsyns_type = [],[]\n",
    "for i in range(len(pre)):\n",
    "    for j in range(len(main_types[i])):\n",
    "        f,s = binomial_CI(main_types[i][j],bins_25)\n",
    "        f_type.append(f)\n",
    "        s_type.append(s)\n",
    "#         sf,ss = binomial_CI(syn_types[i][j],bins_25)\n",
    "#         synf_type.append(sf)\n",
    "#         syns_type.append(ss)\n",
    "#         nf,ns = binomial_CI(nonsyn_types[i][j],bins_25)\n",
    "#         nonsynf_type.append(nf)\n",
    "#         nonsyns_type.append(ns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5d6d0c-b0b1-4449-8be6-25eb787dacb5",
   "metadata": {},
   "source": [
    "Finally, this cell will create a pdf of the 33-panel plot for each pre-synaptic root_id inside of the table \"pre\". Arguments are as follows:\n",
    "- first argument is the bin array, which will look like [0, 25, 50, 75,...etc] depending on how it was defined in a previous cell\n",
    "- second argument is the synaptic table split into types\n",
    "- third argument is the non-synaptic table, also split into types\n",
    "- fourth argument is the pre-synaptic table (just one row)\n",
    "- fifth argument is the filename\n",
    "\n",
    "I chose the filename to be the root_id of the pre-synaptic cell, but an alternate example is included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6318d581-b658-4df4-aa4d-d2b321d7ba02",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(pre)):\n",
    "    # this will give filename = pre-synaptic root_id \"9834639845739683305847\"\n",
    "    filename = '{0:s}'.format(str(np.array(pre[i].pt_root_id)[0]))\n",
    "    # this will give filename = 'BC-4587604586048560456748'\n",
    "    #filename = '{0:s}-{1:s}'.format(str(np.array(pre[i].cell_type)[0]),str(np.array(pre[i].pt_root_id)[0]))\n",
    "    unique_types = np.unique(main[i].cell_type)\n",
    "    threepanels_pertype(bins_25,syn_types[i],nonsyn_types[i],pre[i],filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2be0312-7cac-4972-b6a8-19b7f45a4bf4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331d88b3-75e2-427a-9ebb-632585724910",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
